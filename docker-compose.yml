version: '3.8'

services:
  reddit-scraper:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: reddit-scraper
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config
    environment:
      # Web scraping configuration (no API credentials needed!)
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - RATE_LIMIT_DELAY=${RATE_LIMIT_DELAY:-2.0}
      - POSTS_PER_SUBREDDIT=${POSTS_PER_SUBREDDIT:-25}
      - MAX_USERS_TO_ENRICH=${MAX_USERS_TO_ENRICH:-20}
      - RUN_MODE=${RUN_MODE:-single}
    env_file:
      - .env
    restart: unless-stopped
    networks:
      - reddit-network

  # Optional: Scheduler service for daily monitoring (future enhancement)
  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: reddit-scheduler
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config:/app/config
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - RATE_LIMIT_DELAY=${RATE_LIMIT_DELAY:-2.0}
      - RUN_MODE=scheduler
    env_file:
      - .env
    command: python -m src.scheduler
    restart: unless-stopped
    networks:
      - reddit-network
    profiles:
      - monitoring  # Only start with: docker-compose --profile monitoring up

networks:
  reddit-network:
    driver: bridge

volumes:
  data:
  logs:

